{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/okechukwuchude/Automating-Medical-Coding/blob/main/Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 921,
          "referenced_widgets": [
            "4f5f62eac87a4d42a7c32139c8ecb7a7",
            "ec374625811848e08c60567544d648a1",
            "14dbdaea90324715a168f7591e8eb48d",
            "2f7c57578d8b4908b3a8948799a470bc",
            "b6f4ffd6c5b244f8a7bd5ffd3678a23e",
            "2de20674a3d74872b42ad2062b8581f1",
            "b6ebe390285444c9a5dba67c79df461c",
            "d32cd3c6aeeb44e380595fb609561be3",
            "483c44bec4554ede82495f285d43176c",
            "84d7731978c842c190b12040e91ed5fd",
            "748fd90c77b1431bac28fbc9b39fdd0a",
            "a772903fa9ad4897b91aae1b4d4cbf79",
            "bf189cad37784751bb9b646c878252e7",
            "86455d32ac5642c0b03847bc4bb3a3d1",
            "abd87cfbc9b6479b9bf4c1a0d70cd5a1",
            "851d36bad58d490ba1057877b5b08222",
            "3493b80dab444e5fbbe1647c265e6e01",
            "1a74c9ada2704cb79102e8144bca4726",
            "584f77a1ccee4646b3ec3cc1ad9c1e8d",
            "9b1d7397b9be4b3abecd2ab646b36336",
            "f2adfbefae714b4e93e0d42871070b3d",
            "26e341946878457bb6953ce7ba89cf4a"
          ]
        },
        "id": "mVQTy8zz5YGT",
        "outputId": "61c55459-a7ec-49d4-9e69-ca60e085660a"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "#import stanza\n",
        "import csv\n",
        "import pandas as pd\n",
        "\n",
        "# Build an English pipeline\n",
        "#stanza.download('en', package='mimic', processors={'ner': 'i2b2'}) # download English model\n",
        "#nlp = stanza.Pipeline('en', package='mimic', processors={'ner': 'i2b2'}) # initialize English neural pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [],
      "source": [
        "token_df = pd.read_csv('/home/chudeo/project/full_tokens.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "DfNlyU4X5YGX"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence_id</th>\n",
              "      <th>words</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Baseline</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>artifact</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>.</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>Probable</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>sinus</td>\n",
              "      <td>B</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sentence_id     words labels\n",
              "0            0  Baseline      O\n",
              "1            0  artifact      O\n",
              "2            0         .      O\n",
              "3            1  Probable      O\n",
              "4            1     sinus      B"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "token_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Convert all values in the 'word' column to strings\n",
        "# token_df['word'] = token_df['words'].astype(str)\n",
        "\n",
        "\n",
        "# Drop rows containing non-string values in the 'words' column\n",
        "token_df = token_df.dropna(subset=['words'])  # Drop NaN values\n",
        "token_df = token_df[token_df['words'].apply(lambda x: isinstance(x, str))]  # Filter out non-string values\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "Rv74vtcp5YGY"
      },
      "outputs": [],
      "source": [
        "x = token_df[['sentence_id', 'words']]\n",
        "y = token_df['labels']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Asglnj6Q5YGY"
      },
      "source": [
        "SPLITTING DATA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "EhwK6h0K5YGY"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "RJn_LOG65YGY"
      },
      "outputs": [],
      "source": [
        "#build the training and test data\n",
        "train_data = pd.DataFrame({'sentence_id': x_train['sentence_id'], 'words': x_train['words'], 'labels': y_train})\n",
        "test_data = pd.DataFrame({'sentence_id': x_test['sentence_id'], 'words': x_test['words'], 'labels': y_test})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "GsOyxNBc5YGZ"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence_id</th>\n",
              "      <th>words</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1222807</th>\n",
              "      <td>138</td>\n",
              "      <td>)</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>141314</th>\n",
              "      <td>7</td>\n",
              "      <td>:</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82478</th>\n",
              "      <td>180</td>\n",
              "      <td>First</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>746401</th>\n",
              "      <td>14</td>\n",
              "      <td>hemidiaphragm</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>136123</th>\n",
              "      <td>15</td>\n",
              "      <td>1.5</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1157382</th>\n",
              "      <td>74</td>\n",
              "      <td>ASDIR</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>172635</th>\n",
              "      <td>96</td>\n",
              "      <td>,</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1497529</th>\n",
              "      <td>29</td>\n",
              "      <td>BRONCHOALVEOLAR</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1404898</th>\n",
              "      <td>126</td>\n",
              "      <td>Part</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1359188</th>\n",
              "      <td>290</td>\n",
              "      <td>infection</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1058956 rows Ã— 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         sentence_id            words labels\n",
              "1222807          138                )      O\n",
              "141314             7                :      O\n",
              "82478            180            First      O\n",
              "746401            14    hemidiaphragm      O\n",
              "136123            15              1.5      O\n",
              "...              ...              ...    ...\n",
              "1157382           74            ASDIR      O\n",
              "172635            96                ,      O\n",
              "1497529           29  BRONCHOALVEOLAR      O\n",
              "1404898          126             Part      O\n",
              "1359188          290        infection      O\n",
              "\n",
              "[1058956 rows x 3 columns]"
            ]
          },
          "execution_count": 75,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jlPkrSdb5YGZ"
      },
      "source": [
        "MODEL TRAINING"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qBm7Wbs25YGZ"
      },
      "source": [
        "BERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "84v1Z0LC8GLP"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: simpletransformers in /home/chudeo/using_gpu/lib/python3.9/site-packages (0.70.0)\n",
            "Requirement already satisfied: numpy in /home/chudeo/using_gpu/lib/python3.9/site-packages (from simpletransformers) (1.26.4)\n",
            "Requirement already satisfied: requests in /home/chudeo/using_gpu/lib/python3.9/site-packages (from simpletransformers) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.47.0 in /home/chudeo/using_gpu/lib/python3.9/site-packages (from simpletransformers) (4.66.2)\n",
            "Requirement already satisfied: regex in /home/chudeo/using_gpu/lib/python3.9/site-packages (from simpletransformers) (2023.12.25)\n",
            "Requirement already satisfied: transformers>=4.31.0 in /home/chudeo/using_gpu/lib/python3.9/site-packages (from simpletransformers) (4.39.1)\n",
            "Requirement already satisfied: datasets in /home/chudeo/using_gpu/lib/python3.9/site-packages (from simpletransformers) (2.18.0)\n",
            "Requirement already satisfied: scipy in /home/chudeo/using_gpu/lib/python3.9/site-packages (from simpletransformers) (1.12.0)\n",
            "Requirement already satisfied: scikit-learn in /home/chudeo/using_gpu/lib/python3.9/site-packages (from simpletransformers) (1.4.1.post1)\n",
            "Requirement already satisfied: seqeval in /home/chudeo/using_gpu/lib/python3.9/site-packages (from simpletransformers) (1.2.2)\n",
            "Requirement already satisfied: tensorboard in /home/chudeo/using_gpu/lib/python3.9/site-packages (from simpletransformers) (2.16.2)\n",
            "Requirement already satisfied: tensorboardx in /home/chudeo/using_gpu/lib/python3.9/site-packages (from simpletransformers) (2.6.2.2)\n",
            "Requirement already satisfied: pandas in /home/chudeo/using_gpu/lib/python3.9/site-packages (from simpletransformers) (2.2.1)\n",
            "Requirement already satisfied: tokenizers in /home/chudeo/using_gpu/lib/python3.9/site-packages (from simpletransformers) (0.15.2)\n",
            "Requirement already satisfied: wandb>=0.10.32 in /home/chudeo/using_gpu/lib/python3.9/site-packages (from simpletransformers) (0.16.5)\n",
            "Requirement already satisfied: streamlit in /home/chudeo/using_gpu/lib/python3.9/site-packages (from simpletransformers) (1.32.2)\n",
            "Requirement already satisfied: sentencepiece in /home/chudeo/using_gpu/lib/python3.9/site-packages (from simpletransformers) (0.2.0)\n",
            "Requirement already satisfied: filelock in /home/chudeo/using_gpu/lib/python3.9/site-packages (from transformers>=4.31.0->simpletransformers) (3.13.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /home/chudeo/using_gpu/lib/python3.9/site-packages (from transformers>=4.31.0->simpletransformers) (0.22.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /home/chudeo/using_gpu/lib/python3.9/site-packages (from transformers>=4.31.0->simpletransformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /home/chudeo/using_gpu/lib/python3.9/site-packages (from transformers>=4.31.0->simpletransformers) (6.0.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /home/chudeo/using_gpu/lib/python3.9/site-packages (from transformers>=4.31.0->simpletransformers) (0.4.2)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.1 in /home/chudeo/using_gpu/lib/python3.9/site-packages (from wandb>=0.10.32->simpletransformers) (8.1.7)\n",
            "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /home/chudeo/using_gpu/lib/python3.9/site-packages (from wandb>=0.10.32->simpletransformers) (3.1.42)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /home/chudeo/using_gpu/lib/python3.9/site-packages (from wandb>=0.10.32->simpletransformers) (5.9.8)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /home/chudeo/using_gpu/lib/python3.9/site-packages (from wandb>=0.10.32->simpletransformers) (1.43.0)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /home/chudeo/using_gpu/lib/python3.9/site-packages (from wandb>=0.10.32->simpletransformers) (0.4.0)\n",
            "Requirement already satisfied: setproctitle in /home/chudeo/using_gpu/lib/python3.9/site-packages (from wandb>=0.10.32->simpletransformers) (1.3.3)\n",
            "Requirement already satisfied: setuptools in /home/chudeo/using_gpu/lib/python3.9/site-packages (from wandb>=0.10.32->simpletransformers) (58.1.0)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /home/chudeo/using_gpu/lib/python3.9/site-packages (from wandb>=0.10.32->simpletransformers) (1.4.4)\n",
            "Requirement already satisfied: typing-extensions in /home/chudeo/using_gpu/lib/python3.9/site-packages (from wandb>=0.10.32->simpletransformers) (4.10.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.15.0 in /home/chudeo/using_gpu/lib/python3.9/site-packages (from wandb>=0.10.32->simpletransformers) (4.25.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /home/chudeo/using_gpu/lib/python3.9/site-packages (from requests->simpletransformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/chudeo/using_gpu/lib/python3.9/site-packages (from requests->simpletransformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/chudeo/using_gpu/lib/python3.9/site-packages (from requests->simpletransformers) (2.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/chudeo/using_gpu/lib/python3.9/site-packages (from requests->simpletransformers) (2024.2.2)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /home/chudeo/using_gpu/lib/python3.9/site-packages (from datasets->simpletransformers) (15.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /home/chudeo/using_gpu/lib/python3.9/site-packages (from datasets->simpletransformers) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/chudeo/using_gpu/lib/python3.9/site-packages (from datasets->simpletransformers) (0.3.8)\n",
            "Requirement already satisfied: xxhash in /home/chudeo/using_gpu/lib/python3.9/site-packages (from datasets->simpletransformers) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /home/chudeo/using_gpu/lib/python3.9/site-packages (from datasets->simpletransformers) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.2.0,>=2023.1.0 in /home/chudeo/using_gpu/lib/python3.9/site-packages (from fsspec[http]<=2024.2.0,>=2023.1.0->datasets->simpletransformers) (2024.2.0)\n",
            "Requirement already satisfied: aiohttp in /home/chudeo/using_gpu/lib/python3.9/site-packages (from datasets->simpletransformers) (3.9.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /home/chudeo/using_gpu/lib/python3.9/site-packages (from pandas->simpletransformers) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /home/chudeo/using_gpu/lib/python3.9/site-packages (from pandas->simpletransformers) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /home/chudeo/using_gpu/lib/python3.9/site-packages (from pandas->simpletransformers) (2024.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /home/chudeo/using_gpu/lib/python3.9/site-packages (from scikit-learn->simpletransformers) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/chudeo/using_gpu/lib/python3.9/site-packages (from scikit-learn->simpletransformers) (3.4.0)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /home/chudeo/using_gpu/lib/python3.9/site-packages (from streamlit->simpletransformers) (5.2.0)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /home/chudeo/using_gpu/lib/python3.9/site-packages (from streamlit->simpletransformers) (1.7.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /home/chudeo/using_gpu/lib/python3.9/site-packages (from streamlit->simpletransformers) (5.3.3)\n",
            "Requirement already satisfied: pillow<11,>=7.1.0 in /home/chudeo/using_gpu/lib/python3.9/site-packages (from streamlit->simpletransformers) (10.2.0)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /home/chudeo/using_gpu/lib/python3.9/site-packages (from streamlit->simpletransformers) (13.7.1)\n",
            "Requirement already satisfied: tenacity<9,>=8.1.0 in /home/chudeo/using_gpu/lib/python3.9/site-packages (from streamlit->simpletransformers) (8.2.3)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /home/chudeo/using_gpu/lib/python3.9/site-packages (from streamlit->simpletransformers) (0.10.2)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /home/chudeo/using_gpu/lib/python3.9/site-packages (from streamlit->simpletransformers) (0.8.1b0)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /home/chudeo/using_gpu/lib/python3.9/site-packages (from streamlit->simpletransformers) (6.4)\n",
            "Requirement already satisfied: watchdog>=2.1.5 in /home/chudeo/using_gpu/lib/python3.9/site-packages (from streamlit->simpletransformers) (4.0.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /home/chudeo/using_gpu/lib/python3.9/site-packages (from tensorboard->simpletransformers) (2.1.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /home/chudeo/using_gpu/lib/python3.9/site-packages (from tensorboard->simpletransformers) (1.62.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /home/chudeo/using_gpu/lib/python3.9/site-packages (from tensorboard->simpletransformers) (3.6)\n",
            "Requirement already satisfied: six>1.9 in /home/chudeo/using_gpu/lib/python3.9/site-packages (from tensorboard->simpletransformers) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/chudeo/using_gpu/lib/python3.9/site-packages (from tensorboard->simpletransformers) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /home/chudeo/using_gpu/lib/python3.9/site-packages (from tensorboard->simpletransformers) (3.0.1)\n",
            "Requirement already satisfied: jinja2 in /home/chudeo/using_gpu/lib/python3.9/site-packages (from altair<6,>=4.0->streamlit->simpletransformers) (3.1.3)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /home/chudeo/using_gpu/lib/python3.9/site-packages (from altair<6,>=4.0->streamlit->simpletransformers) (4.21.1)\n",
            "Requirement already satisfied: toolz in /home/chudeo/using_gpu/lib/python3.9/site-packages (from altair<6,>=4.0->streamlit->simpletransformers) (0.12.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /home/chudeo/using_gpu/lib/python3.9/site-packages (from aiohttp->datasets->simpletransformers) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /home/chudeo/using_gpu/lib/python3.9/site-packages (from aiohttp->datasets->simpletransformers) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /home/chudeo/using_gpu/lib/python3.9/site-packages (from aiohttp->datasets->simpletransformers) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /home/chudeo/using_gpu/lib/python3.9/site-packages (from aiohttp->datasets->simpletransformers) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /home/chudeo/using_gpu/lib/python3.9/site-packages (from aiohttp->datasets->simpletransformers) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /home/chudeo/using_gpu/lib/python3.9/site-packages (from aiohttp->datasets->simpletransformers) (4.0.3)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /home/chudeo/using_gpu/lib/python3.9/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb>=0.10.32->simpletransformers) (4.0.11)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /home/chudeo/using_gpu/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard->simpletransformers) (7.1.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/chudeo/using_gpu/lib/python3.9/site-packages (from rich<14,>=10.14.0->streamlit->simpletransformers) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/chudeo/using_gpu/lib/python3.9/site-packages (from rich<14,>=10.14.0->streamlit->simpletransformers) (2.17.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/chudeo/using_gpu/lib/python3.9/site-packages (from werkzeug>=1.0.1->tensorboard->simpletransformers) (2.1.5)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /home/chudeo/using_gpu/lib/python3.9/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb>=0.10.32->simpletransformers) (5.0.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /home/chudeo/using_gpu/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->simpletransformers) (3.18.1)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/chudeo/using_gpu/lib/python3.9/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit->simpletransformers) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /home/chudeo/using_gpu/lib/python3.9/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit->simpletransformers) (0.34.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /home/chudeo/using_gpu/lib/python3.9/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit->simpletransformers) (0.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /home/chudeo/using_gpu/lib/python3.9/site-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit->simpletransformers) (0.1.2)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install simpletransformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [],
      "source": [
        "from simpletransformers.ner import NERModel, NERArgs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "T_vkewDE5YGZ"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['O', 'B', 'I']"
            ]
          },
          "execution_count": 78,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "label = token_df['labels'].unique().tolist()\n",
        "label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "g6ARG3Ft5YGZ"
      },
      "outputs": [],
      "source": [
        "args = NERArgs()\n",
        "args.num_train_epochs = 10\n",
        "args.learning_rate = 1e-4\n",
        "args.overwrite_output_dir = True\n",
        "args.train_batch_size = 32\n",
        "args.eval_batch_size = 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "FY3cKkzi5YGZ"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "model = NERModel('bert', 'bert-base-cased', labels=label, args=args, use_cuda = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "hfrXnHMp5YGa"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c1176233656148c0aeb0704ca02f9fc5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "746eb556a1a44158b9de5d80505fd3e5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch:   0%|          | 0/10 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "27d7c58ac42c4e97a543686511172405",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Running Epoch 1 of 10:   0%|          | 0/17 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/chudeo/using_gpu/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:139: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "76033dd2af804a08a32fc2753621e5f0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Running Epoch 2 of 10:   0%|          | 0/17 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e5bbf2fa532b41c3bb220c53221f56ae",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Running Epoch 3 of 10:   0%|          | 0/17 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6f5832b4ffc1432c92ab0b153c1f5626",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Running Epoch 4 of 10:   0%|          | 0/17 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ba03f83524434c6f9df6153799ce8df2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Running Epoch 5 of 10:   0%|          | 0/17 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "906f676de64f47d8bcfc39357816c8db",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Running Epoch 6 of 10:   0%|          | 0/17 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5f4d9c5b03364129b0ff73c52c2e7f2f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Running Epoch 7 of 10:   0%|          | 0/17 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cc8efc8ccbc44b6abc97295eaaebe3fc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Running Epoch 8 of 10:   0%|          | 0/17 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1711f37496ca4195ac28c9b76f934eb9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Running Epoch 9 of 10:   0%|          | 0/17 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d25d621c9e4a40cf905ab2549d5bbcc4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Running Epoch 10 of 10:   0%|          | 0/17 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "(170, 0.06701843880548361)"
            ]
          },
          "execution_count": 81,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Train the model\n",
        "model.train_model(train_data, eval_data=test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "xwSLsu2O5YGa"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c93d0a316bf04bccb549a43613057a5c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "11929d338db24bf2be732fde75e2db71",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Running Evaluation:   0%|          | 0/16 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "result, model_outputs, preds_list = model.eval_model(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "gr6l7MSn5YGa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'eval_loss': 0.056901418953202665,\n",
              " 'precision': 0.3305785123966942,\n",
              " 'recall': 0.15810276679841898,\n",
              " 'f1_score': 0.21390374331550802}"
            ]
          },
          "execution_count": 83,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "f_e0uNX75YGa"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a97802a958914ec49e6d989b8135b30d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "de5bba70560744c1a43e64645a219b26",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Running Prediction:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "prediction, model_output = model.predict(['There is also intraventricular extension into the ipsilateral and contralateral lateral ventricles.'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "Vy3i95FQ5YGa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[{'There': 'O'},\n",
              "  {'is': 'O'},\n",
              "  {'also': 'O'},\n",
              "  {'intraventricular': 'I'},\n",
              "  {'extension': 'I'},\n",
              "  {'into': 'I'},\n",
              "  {'the': 'I'},\n",
              "  {'ipsilateral': 'I'},\n",
              "  {'and': 'I'},\n",
              "  {'contralateral': 'I'},\n",
              "  {'lateral': 'I'},\n",
              "  {'ventricles.': 'I'}]]"
            ]
          },
          "execution_count": 85,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9D3Tk8UWQBJv"
      },
      "source": [
        "BioBERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "Hi0g_eWJ5YGa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['O', 'B', 'I']"
            ]
          },
          "execution_count": 86,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bio_label = token_df['labels'].unique().tolist()\n",
        "bio_label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "9kHxJQYYQTel"
      },
      "outputs": [],
      "source": [
        "# Initialize NER model arguments\n",
        "args = NERArgs()\n",
        "args.num_train_epochs = 10  # Number of training epochs\n",
        "args.learning_rate = 2e-5   # Learning rate\n",
        "args.overwrite_output_dir = True\n",
        "args.train_batch_size = 32\n",
        "args.eval_batch_size = 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "Ou10vzvJQdfi"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at dmis-lab/biobert-base-cased-v1.2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "# Create the NER model with BioBERT\n",
        "model = NERModel('bert', 'dmis-lab/biobert-base-cased-v1.2', args=args, labels=bio_label, use_cuda=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "NA2PHOJWQhz2"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c97442748bb8467f979951b5818146a6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "337e29958a11420a9c5c5daa8f891e7f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch:   0%|          | 0/10 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "522972f74fa24ebd88ba412b95209fa4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Running Epoch 1 of 10:   0%|          | 0/17 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a315a6d77acf4a939aa8bd69c3cab984",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Running Epoch 2 of 10:   0%|          | 0/17 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6dc3f82a27624265b605449bdd98e4c8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Running Epoch 3 of 10:   0%|          | 0/17 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "52b0b30a282545ff9103b2a086309702",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Running Epoch 4 of 10:   0%|          | 0/17 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "60764a9b1b2f4b998724663e12e68a94",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Running Epoch 5 of 10:   0%|          | 0/17 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "05da1c0fbe474b7198bf06e4cdba8bdd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Running Epoch 6 of 10:   0%|          | 0/17 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "828a32f6881b406e9e882ed89477c039",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Running Epoch 7 of 10:   0%|          | 0/17 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d7f03cfb864d4d10bf8976315eee8af1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Running Epoch 8 of 10:   0%|          | 0/17 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c2194c55eb174364b29671102c5bbbee",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Running Epoch 9 of 10:   0%|          | 0/17 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0019bca33f5d43cf8359ba0fe941abf4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Running Epoch 10 of 10:   0%|          | 0/17 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1c760d1b57a2417aa02e69721752dd42",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "84e8b4a732b44304b8a180ae6e43e2c2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Running Evaluation:   0%|          | 0/16 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Train the model\n",
        "model.train_model(train_data)\n",
        "\n",
        "# Evaluate the model on test data\n",
        "bio_result, model_outputs, preds_list = model.eval_model(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "5FYSrL28Qsw4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'eval_loss': 0.03991517031681724,\n",
              " 'precision': 0.4473684210526316,\n",
              " 'recall': 0.06719367588932806,\n",
              " 'f1_score': 0.11683848797250859}"
            ]
          },
          "execution_count": 90,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bio_result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "fCaCaRTAQ-Fb"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f2e104c9225f4143a7d5f4ca16601ab3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0b649c9d681b42a7843c87df70548455",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Running Prediction:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[{'T[**Name2': 'O'}, {'(NI)': 'O'}, {'**]': 'O'}, {'was': 'O'}, {'extubated': 'O'}, {'on': 'O'}, {'[**10-24**]': 'O'}, {'without': 'O'}]]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "predictions, raw_outputs = model.predict([\"T[**Name2 (NI) **] was extubated on [**10-24**] without\"])\n",
        "print(predictions)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {},
      "outputs": [],
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "# Build the training, validation, and test data\n",
        "train_data = pd.DataFrame({'sentence_id': x_train['sentence_id'], 'words': x_train['words'], 'labels': y_train})\n",
        "val_data = pd.DataFrame({'sentence_id': x_val['sentence_id'], 'words': x_val['words'], 'labels': y_val})\n",
        "test_data = pd.DataFrame({'sentence_id': x_test['sentence_id'], 'words': x_test['words'], 'labels': y_test})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "LGe9kS8iQ_fX"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at dmis-lab/biobert-base-cased-v1.2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "2024-03-27 22:41:21,557 [INFO] Training with lr=1e-05, epochs=1, batch_size=16\n",
            "2024-03-27 22:41:21,557 [INFO] Training with lr=1e-05, epochs=1, batch_size=16\n",
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at dmis-lab/biobert-base-cased-v1.2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a8150f3a67e549c6a3be0984b437ffcb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f63436053db14530b62de125a0c7384f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0c5c85a7730c45acb0bfaaeb1ced43d9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Running Epoch 1 of 1:   0%|          | 0/32 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6f03764b935e4539b67e2fca433db47f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f344a514c3dd4f768583310ad6036dfc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Running Evaluation:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/chudeo/using_gpu/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "Found input variables with inconsistent numbers of samples: [211792, 498]",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[94], line 60\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[39m# Evaluate on validation set\u001b[39;00m\n\u001b[1;32m     59\u001b[0m _, _, val_preds \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39meval_model(val_data)\n\u001b[0;32m---> 60\u001b[0m val_accuracy \u001b[39m=\u001b[39m accuracy_score(val_data[\u001b[39m'\u001b[39;49m\u001b[39mlabels\u001b[39;49m\u001b[39m'\u001b[39;49m], val_preds)\n\u001b[1;32m     62\u001b[0m \u001b[39m# Check for early stopping\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[39mif\u001b[39;00m val_accuracy \u001b[39m>\u001b[39m best_val_accuracy:\n",
            "File \u001b[0;32m~/using_gpu/lib/python3.9/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    214\u001b[0m \u001b[39mexcept\u001b[39;00m InvalidParameterError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[39m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[39m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[39m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[39m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw+ must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[39mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
            "File \u001b[0;32m~/using_gpu/lib/python3.9/site-packages/sklearn/metrics/_classification.py:213\u001b[0m, in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Accuracy classification score.\u001b[39;00m\n\u001b[1;32m    148\u001b[0m \n\u001b[1;32m    149\u001b[0m \u001b[39mIn multilabel classification, this function computes subset accuracy:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[39m0.5\u001b[39;00m\n\u001b[1;32m    210\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    212\u001b[0m \u001b[39m# Compute accuracy for each possible representation\u001b[39;00m\n\u001b[0;32m--> 213\u001b[0m y_type, y_true, y_pred \u001b[39m=\u001b[39m _check_targets(y_true, y_pred)\n\u001b[1;32m    214\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[1;32m    215\u001b[0m \u001b[39mif\u001b[39;00m y_type\u001b[39m.\u001b[39mstartswith(\u001b[39m\"\u001b[39m\u001b[39mmultilabel\u001b[39m\u001b[39m\"\u001b[39m):\n",
            "File \u001b[0;32m~/using_gpu/lib/python3.9/site-packages/sklearn/metrics/_classification.py:85\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_check_targets\u001b[39m(y_true, y_pred):\n\u001b[1;32m     59\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Check that y_true and y_pred belong to the same classification task.\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \n\u001b[1;32m     61\u001b[0m \u001b[39m    This converts multiclass or binary types to a common shape, and raises a\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[39m    y_pred : array or indicator matrix\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 85\u001b[0m     check_consistent_length(y_true, y_pred)\n\u001b[1;32m     86\u001b[0m     type_true \u001b[39m=\u001b[39m type_of_target(y_true, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my_true\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     87\u001b[0m     type_pred \u001b[39m=\u001b[39m type_of_target(y_pred, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my_pred\u001b[39m\u001b[39m\"\u001b[39m)\n",
            "File \u001b[0;32m~/using_gpu/lib/python3.9/site-packages/sklearn/utils/validation.py:457\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    455\u001b[0m uniques \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(lengths)\n\u001b[1;32m    456\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(uniques) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m--> 457\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    458\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    459\u001b[0m         \u001b[39m%\u001b[39m [\u001b[39mint\u001b[39m(l) \u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m lengths]\n\u001b[1;32m    460\u001b[0m     )\n",
            "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [211792, 498]"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from simpletransformers.ner import NERModel, NERArgs\n",
        "import logging\n",
        "\n",
        "\n",
        "# Define hyperparameters to search over\n",
        "param_grid = {\n",
        "    'learning_rate': [1e-5, 2e-5, 3e-5],\n",
        "    'num_train_epochs': [1, 2, 3],\n",
        "    'train_batch_size': [16, 32, 64]\n",
        "}\n",
        "\n",
        "# Initialize your model\n",
        "model = NERModel('bert', 'dmis-lab/biobert-base-cased-v1.2', args=args, labels=bio_label, use_cuda=True)\n",
        "\n",
        "best_accuracy = 0\n",
        "best_params = {}\n",
        "\n",
        "# Split test_data into batches to avoid memory issues\n",
        "test_batches = [test_data[i:i+32] for i in range(0, len(test_data), 32)]\n",
        "\n",
        "# Define early stopping criteria\n",
        "early_stop_patience = 3\n",
        "early_stop_counter = 0\n",
        "best_val_accuracy = 0\n",
        "\n",
        "\n",
        "# Configure logging\n",
        "logger = logging.getLogger(__name__)\n",
        "logger.setLevel(logging.INFO)\n",
        "file_handler = logging.FileHandler('training.log')\n",
        "stream_handler = logging.StreamHandler()\n",
        "formatter = logging.Formatter('%(asctime)s [%(levelname)s] %(message)s')\n",
        "file_handler.setFormatter(formatter)\n",
        "stream_handler.setFormatter(formatter)\n",
        "logger.addHandler(file_handler)\n",
        "logger.addHandler(stream_handler)\n",
        "\n",
        "\n",
        "# Perform manual hyperparameter tuning\n",
        "for lr in param_grid['learning_rate']:\n",
        "    for epochs in param_grid['num_train_epochs']:\n",
        "        for batch_size in param_grid['train_batch_size']:\n",
        "            logger.info(f\"Training with lr={lr}, epochs={epochs}, batch_size={batch_size}\")\n",
        "\n",
        "            # Initialize the model with current hyperparameters\n",
        "            args = NERArgs()\n",
        "            args.learning_rate = lr\n",
        "            args.num_train_epochs = epochs\n",
        "            args.train_batch_size = batch_size\n",
        "            model = NERModel('bert', 'dmis-lab/biobert-base-cased-v1.2', args=args, labels=bio_label, use_cuda=True)\n",
        "\n",
        "\n",
        "            # Train the model\n",
        "            for epoch in range(epochs):\n",
        "                model.train_model(train_data)\n",
        "\n",
        "                # Evaluate on validation set\n",
        "                _, _, val_preds = model.eval_model(val_data)\n",
        "                val_accuracy = accuracy_score(val_data['labels'], val_preds)\n",
        "\n",
        "                # Check for early stopping\n",
        "                if val_accuracy > best_val_accuracy:\n",
        "                    best_val_accuracy = val_accuracy\n",
        "                    early_stop_counter = 0\n",
        "                else:\n",
        "                    early_stop_counter += 1\n",
        "                    if early_stop_counter >= early_stop_patience:\n",
        "                        logger.info(f\"Early stopping after {epoch + 1} epochs.\")\n",
        "                        break\n",
        "\n",
        "            # Evaluate on test set\n",
        "            _, _, test_preds = model.eval_model(test_data)\n",
        "            accuracy = accuracy_score(test_data['labels'], test_preds)\n",
        "            logger.info(f\"Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "            # Update best parameters and accuracy\n",
        "            if accuracy > best_accuracy:\n",
        "                best_accuracy = accuracy\n",
        "                best_params = {'learning_rate': lr, 'num_train_epochs': epochs, 'train_batch_size': batch_size}\n",
        "\n",
        "# Log best hyperparameters and accuracy\n",
        "logger.info(\"Best Parameters: %s\", str(best_params))\n",
        "logger.info(\"Best Accuracy: %.4f\", best_accuracy)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Regularization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at dmis-lab/biobert-base-cased-v1.2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8262c96d004a4dda9aa6fe5f14e1008a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1b26ede98a7b444fa348a58c79dbcd24",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "eda07ba3dd2a447d9d745b89643cdfc2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Running Epoch 1 of 5:   0%|          | 0/16 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "39258464e8b24dd4af9d851918a3061c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Running Epoch 2 of 5:   0%|          | 0/16 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e4ae457d38ca457f97af955301411886",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Running Epoch 3 of 5:   0%|          | 0/16 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "52cba430ce654ebba305c0ef19e2f2ee",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Running Epoch 4 of 5:   0%|          | 0/16 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2b516e809cd843adb30986eb17aff0bb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Running Epoch 5 of 5:   0%|          | 0/16 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e134e3e62e2a4d8097d3f295b6d863e6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8e1334ff67bb4f76b739fc7e5daaa0a1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Running Evaluation:   0%|          | 0/16 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.046454982104478404, 'precision': 0.0, 'recall': 0.0, 'f1_score': 0.0}\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Define regularization parameters\n",
        "args = NERArgs()\n",
        "args.num_train_epochs = 5\n",
        "args.learning_rate = 2e-5\n",
        "args.overwrite_output_dir = True\n",
        "args.train_batch_size = 32\n",
        "args.eval_batch_size = 32\n",
        "args.weight_decay = 0.01  # Example regularization parameter\n",
        "\n",
        "# Initialize the model with regularization\n",
        "model = NERModel('bert', 'dmis-lab/biobert-base-cased-v1.2', args=args, labels=bio_label, use_cuda=False)\n",
        "\n",
        "# Train the model\n",
        "model.train_model(train_data)\n",
        "\n",
        "# Evaluate the model\n",
        "result, model_outputs, preds_list = model.eval_model(test_data)\n",
        "print(result)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'eval_loss': 0.046454982104478404,\n",
              " 'precision': 0.0,\n",
              " 'recall': 0.0,\n",
              " 'f1_score': 0.0}"
            ]
          },
          "execution_count": 96,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Fine-tuning BERT for named-entity recognition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence_id</th>\n",
              "      <th>words</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Baseline</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>artifact</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>.</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>Probable</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>sinus</td>\n",
              "      <td>B</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1513257</th>\n",
              "      <td>134</td>\n",
              "      <td>(</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1513258</th>\n",
              "      <td>134</td>\n",
              "      <td>2</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1513259</th>\n",
              "      <td>134</td>\n",
              "      <td>)</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1513260</th>\n",
              "      <td>134</td>\n",
              "      <td>7284</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1513261</th>\n",
              "      <td>134</td>\n",
              "      <td>**]</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1512795 rows Ã— 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         sentence_id     words labels\n",
              "0                  0  Baseline      O\n",
              "1                  0  artifact      O\n",
              "2                  0         .      O\n",
              "3                  1  Probable      O\n",
              "4                  1     sinus      B\n",
              "...              ...       ...    ...\n",
              "1513257          134         (      O\n",
              "1513258          134         2      O\n",
              "1513259          134         )      O\n",
              "1513260          134      7284      O\n",
              "1513261          134       **]      O\n",
              "\n",
              "[1512795 rows x 3 columns]"
            ]
          },
          "execution_count": 97,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "token_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'O': 0, 'B': 1, 'I': 2}"
            ]
          },
          "execution_count": 98,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "label2id = {k: v for v, k in enumerate(token_df.labels.unique())}\n",
        "id2label = {v: k for v, k in enumerate(token_df.labels.unique())}\n",
        "label2id"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### **Preparing the dataset and dataloader**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import BertTokenizer, BertForMaskedLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {},
      "outputs": [],
      "source": [
        "MAX_LEN = 128\n",
        "TRAIN_BATCH_SIZE = 4\n",
        "VALID_BATCH_SIZE = 2\n",
        "EPOCHS = 1\n",
        "LEARNING_RATE = 1e-05\n",
        "MAX_GRAD_NORM = 10\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class dataset(Dataset):\n",
        "    def __init__(self, dataframe, tokenizer, max_len):\n",
        "        self.len = len(dataframe)\n",
        "        self.data = dataframe\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        words = self.data.iloc[index]['words'].split(\",\")  # Assuming tokenized words are separated by comma\n",
        "        labels = self.data.iloc[index]['labels'].split(\",\")\n",
        "\n",
        "        # Convert tokenized words to token IDs\n",
        "        input_ids = [self.tokenizer.convert_tokens_to_ids(word.split()) for word in words]\n",
        "\n",
        "        # Pad or truncate tokenized words and labels to fit MAX_LEN\n",
        "        if len(input_ids) > self.max_len:\n",
        "            input_ids = input_ids[:self.max_len]\n",
        "            labels = labels[:self.max_len]\n",
        "        elif len(input_ids) < self.max_len:\n",
        "            padding_length = self.max_len - len(input_ids)\n",
        "            input_ids += [[0]] * padding_length  # Padding token ID assumed to be 0\n",
        "            labels += ['O'] * padding_length\n",
        "\n",
        "        # Flatten the list of token IDs\n",
        "        input_ids = [token_id for sublist in input_ids for token_id in sublist]\n",
        "\n",
        "        # Convert labels to label ids\n",
        "        label_ids = [label2id[label] for label in labels]\n",
        "\n",
        "        # Create attention mask\n",
        "        attention_mask = [1 if token_id != 0 else 0 for token_id in input_ids]  # Assuming padding token ID is 0\n",
        "\n",
        "        return {\n",
        "            'ids': torch.tensor(input_ids, dtype=torch.long),\n",
        "            'mask': torch.tensor(attention_mask, dtype=torch.long),\n",
        "            'targets': torch.tensor(label_ids, dtype=torch.long)\n",
        "        }\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.len\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "# def collate_fn(batch):\n",
        "#     # Get input_ids, masks, and targets from the batch\n",
        "#     ids = [sample['ids'] for sample in batch]\n",
        "#     masks = [sample['mask'] for sample in batch]\n",
        "#     targets = [sample['targets'] for sample in batch]\n",
        "\n",
        "#     # Pad sequences to the length of the longest sequence in the batch\n",
        "#     ids = pad_sequence(ids, batch_first=True, padding_value=tokenizer.pad_token_id)\n",
        "#     masks = pad_sequence(masks, batch_first=True, padding_value=0)  # Padding token ID is assumed to be 0\n",
        "#     targets = pad_sequence(targets, batch_first=True, padding_value=-100)  # Replace -100 with appropriate padding value for labels\n",
        "\n",
        "#     # Ensure alignment between input_ids, masks, and targets\n",
        "#     masks = masks.bool()  # Convert to boolean mask\n",
        "#     targets = targets * masks.long()  # Apply mask to targets\n",
        "\n",
        "#     return {\n",
        "#         'ids': ids,\n",
        "#         'mask': masks,\n",
        "#         'targets': targets\n",
        "#     }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {},
      "outputs": [],
      "source": [
        "def collate_fn(batch):\n",
        "    ids = [sample['ids'] for sample in batch]\n",
        "    masks = [sample['mask'] for sample in batch]\n",
        "    targets = [sample['targets'] for sample in batch]\n",
        "\n",
        "    # Pad sequences dynamically to the maximum length within the batch\n",
        "    max_len = max(len(seq) for seq in ids)\n",
        "    ids = [torch.nn.functional.pad(seq, (0, max_len - len(seq)), value=0) for seq in ids]\n",
        "    masks = [torch.nn.functional.pad(seq, (0, max_len - len(seq)), value=0) for seq in masks]\n",
        "    targets = [torch.nn.functional.pad(seq, (0, max_len - len(seq)), value=-100) for seq in targets]\n",
        "\n",
        "    ids = torch.stack(ids, dim=0)\n",
        "    masks = torch.stack(masks, dim=0)\n",
        "    targets = torch.stack(targets, dim=0)\n",
        "\n",
        "    return {\n",
        "        'ids': ids,\n",
        "        'mask': masks,\n",
        "        'targets': targets\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FULL Dataset: (1512795, 3)\n",
            "TRAIN Dataset: (1210236, 3)\n",
            "TEST Dataset: (302559, 3)\n"
          ]
        }
      ],
      "source": [
        "# Define train and test datasets using train_test_split\n",
        "train_df, test_df = train_test_split(token_df, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"FULL Dataset: {}\".format(token_df.shape))\n",
        "print(\"TRAIN Dataset: {}\".format(train_df.shape))\n",
        "print(\"TEST Dataset: {}\".format(test_df.shape))\n",
        "\n",
        "# Create dataset instances\n",
        "training_set = dataset(train_df, tokenizer, MAX_LEN)\n",
        "testing_set = dataset(test_df, tokenizer, MAX_LEN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'ids': tensor([100,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0]),\n",
              " 'mask': tensor([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
              " 'targets': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0])}"
            ]
          },
          "execution_count": 105,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "training_set[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([100,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0])"
            ]
          },
          "execution_count": 106,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "training_set[0][\"ids\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[UNK]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n"
          ]
        }
      ],
      "source": [
        "# print the first 30 tokens and corresponding labels\n",
        "for token, label in zip(tokenizer.convert_ids_to_tokens(training_set[0][\"ids\"][:30]), training_set[0][\"targets\"][:30]):\n",
        "  print('{0:10}  {1}'.format(token, id2label[label.item()]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, let's define the corresponding PyTorch dataloaders:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
        "                'shuffle': True,\n",
        "                'num_workers': 0\n",
        "                }\n",
        "\n",
        "test_params = {'batch_size': VALID_BATCH_SIZE,\n",
        "                'shuffle': True,\n",
        "                'num_workers': 0\n",
        "                }\n",
        "\n",
        "# training_loader = DataLoader(training_set, **train_params)\n",
        "# testing_loader = DataLoader(testing_set, **test_params)\n",
        "\n",
        "training_loader = DataLoader(training_set, collate_fn=collate_fn, **train_params)\n",
        "testing_loader = DataLoader(testing_set, collate_fn=collate_fn, **test_params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### **Defining the model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "from transformers import BertTokenizer, BertConfig, BertForTokenClassification\n",
        "\n",
        "\n",
        "from torch import cuda\n",
        "device = 'cuda' if cuda.is_available() else 'cpu'\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "BertForTokenClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 110,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = BertForTokenClassification.from_pretrained('bert-base-uncased', \n",
        "                                                   num_labels=len(id2label),\n",
        "                                                   id2label=id2label,\n",
        "                                                   label2id=label2id)\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### **Training the model**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(1.5896, device='cuda:0', grad_fn=<NllLossBackward0>)"
            ]
          },
          "execution_count": 112,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ids = training_set[0][\"ids\"].unsqueeze(0)\n",
        "mask = training_set[0][\"mask\"].unsqueeze(0)\n",
        "targets = training_set[0][\"targets\"].unsqueeze(0)\n",
        "ids = ids.to(device)\n",
        "mask = mask.to(device)\n",
        "targets = targets.to(device)\n",
        "outputs = model(input_ids=ids, attention_mask=mask, labels=targets)\n",
        "initial_loss = outputs[0]\n",
        "initial_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1, 128, 3])"
            ]
          },
          "execution_count": 113,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tr_logits = outputs[1]\n",
        "tr_logits.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {},
      "outputs": [],
      "source": [
        "optimizer = torch.optim.Adam(params=model.parameters(), lr=LEARNING_RATE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Defining the training function on the 80% of the dataset for tuning the bert model\n",
        "def train(epoch):\n",
        "    tr_loss, tr_accuracy = 0, 0\n",
        "    nb_tr_examples, nb_tr_steps = 0, 0\n",
        "    tr_preds, tr_labels = [], []\n",
        "    # put model in training mode\n",
        "    model.train()\n",
        "    \n",
        "    for idx, batch in enumerate(training_loader):\n",
        "        \n",
        "        ids = batch['ids'].to(device, dtype = torch.long)\n",
        "        mask = batch['mask'].to(device, dtype = torch.long)\n",
        "        targets = batch['targets'].to(device, dtype = torch.long)\n",
        "\n",
        "        outputs = model(input_ids=ids, attention_mask=mask, labels=targets)\n",
        "        loss, tr_logits = outputs.loss, outputs.logits\n",
        "        tr_loss += loss.item()\n",
        "\n",
        "        nb_tr_steps += 1\n",
        "        nb_tr_examples += targets.size(0)\n",
        "        \n",
        "        if idx % 100==0:\n",
        "            loss_step = tr_loss/nb_tr_steps\n",
        "            print(f\"Training loss per 100 training steps: {loss_step}\")\n",
        "           \n",
        "        # compute training accuracy\n",
        "        flattened_targets = targets.view(-1) # shape (batch_size * seq_len,)\n",
        "        active_logits = tr_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
        "        flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n",
        "        # now, use mask to determine where we should compare predictions with targets (includes [CLS] and [SEP] token predictions)\n",
        "        active_accuracy = mask.view(-1) == 1 # active accuracy is also of shape (batch_size * seq_len,)\n",
        "        targets = torch.masked_select(flattened_targets, active_accuracy)\n",
        "        predictions = torch.masked_select(flattened_predictions, active_accuracy)\n",
        "        \n",
        "        tr_preds.extend(predictions)\n",
        "        tr_labels.extend(targets)\n",
        "        \n",
        "        tmp_tr_accuracy = accuracy_score(targets.cpu().numpy(), predictions.cpu().numpy())\n",
        "        tr_accuracy += tmp_tr_accuracy\n",
        "    \n",
        "        # gradient clipping\n",
        "        torch.nn.utils.clip_grad_norm_(\n",
        "            parameters=model.parameters(), max_norm=MAX_GRAD_NORM\n",
        "        )\n",
        "        \n",
        "        # backward pass\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    epoch_loss = tr_loss / nb_tr_steps\n",
        "    tr_accuracy = tr_accuracy / nb_tr_steps\n",
        "    print(f\"Training loss epoch: {epoch_loss}\")\n",
        "    print(f\"Training accuracy epoch: {tr_accuracy}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training epoch: 1\n",
            "Training loss per 100 training steps: 1.0059914588928223\n",
            "Training loss per 100 training steps: 0.1206019668895198\n",
            "Training loss per 100 training steps: 0.06339988990835105\n",
            "Training loss per 100 training steps: 0.04348713418923665\n",
            "Training loss per 100 training steps: 0.03345326216603418\n",
            "Training loss per 100 training steps: 0.027170831256243075\n",
            "Training loss per 100 training steps: 0.023015102398255993\n",
            "Training loss per 100 training steps: 0.019953243587629076\n",
            "Training loss per 100 training steps: 0.017570019693601616\n",
            "Training loss per 100 training steps: 0.015828961418689922\n",
            "Training loss per 100 training steps: 0.014477360259951349\n",
            "Training loss per 100 training steps: 0.0132739151566876\n",
            "Training loss per 100 training steps: 0.012310035926197092\n",
            "Training loss per 100 training steps: 0.011576611617931987\n",
            "Training loss per 100 training steps: 0.010869534927597143\n",
            "Training loss per 100 training steps: 0.010281310765121798\n",
            "Training loss per 100 training steps: 0.009711871385027677\n",
            "Training loss per 100 training steps: 0.009197322377687096\n",
            "Training loss per 100 training steps: 0.008800600235367106\n",
            "Training loss per 100 training steps: 0.008435681348146078\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(EPOCHS):\n",
        "    print(f\"Training epoch: {epoch + 1}\")\n",
        "    train(epoch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### **Evaluating the model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def valid(model, testing_loader):\n",
        "    # put model in evaluation mode\n",
        "    model.eval()\n",
        "    \n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_examples, nb_eval_steps = 0, 0\n",
        "    eval_preds, eval_labels = [], []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for idx, batch in enumerate(testing_loader):\n",
        "            \n",
        "            ids = batch['ids'].to(device, dtype = torch.long)\n",
        "            mask = batch['mask'].to(device, dtype = torch.long)\n",
        "            targets = batch['targets'].to(device, dtype = torch.long)\n",
        "            \n",
        "            outputs = model(input_ids=ids, attention_mask=mask, labels=targets)\n",
        "            loss, eval_logits = outputs.loss, outputs.logits\n",
        "            \n",
        "            eval_loss += loss.item()\n",
        "\n",
        "            nb_eval_steps += 1\n",
        "            nb_eval_examples += targets.size(0)\n",
        "        \n",
        "            if idx % 100==0:\n",
        "                loss_step = eval_loss/nb_eval_steps\n",
        "                print(f\"Validation loss per 100 evaluation steps: {loss_step}\")\n",
        "              \n",
        "            # compute evaluation accuracy\n",
        "            flattened_targets = targets.view(-1) # shape (batch_size * seq_len,)\n",
        "            active_logits = eval_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
        "            flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n",
        "            # now, use mask to determine where we should compare predictions with targets (includes [CLS] and [SEP] token predictions)\n",
        "            active_accuracy = mask.view(-1) == 1 # active accuracy is also of shape (batch_size * seq_len,)\n",
        "            targets = torch.masked_select(flattened_targets, active_accuracy)\n",
        "            predictions = torch.masked_select(flattened_predictions, active_accuracy)\n",
        "            \n",
        "            eval_labels.extend(targets)\n",
        "            eval_preds.extend(predictions)\n",
        "            \n",
        "            tmp_eval_accuracy = accuracy_score(targets.cpu().numpy(), predictions.cpu().numpy())\n",
        "            eval_accuracy += tmp_eval_accuracy\n",
        "    \n",
        "    #print(eval_labels)\n",
        "    #print(eval_preds)\n",
        "\n",
        "    labels = [id2label[id.item()] for id in eval_labels]\n",
        "    predictions = [id2label[id.item()] for id in eval_preds]\n",
        "\n",
        "    #print(labels)\n",
        "    #print(predictions)\n",
        "    \n",
        "    eval_loss = eval_loss / nb_eval_steps\n",
        "    eval_accuracy = eval_accuracy / nb_eval_steps\n",
        "    print(f\"Validation Loss: {eval_loss}\")\n",
        "    print(f\"Validation Accuracy: {eval_accuracy}\")\n",
        "\n",
        "    return labels, predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "labels, predictions = valid(model, testing_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from seqeval.metrics import classification_report\n",
        "\n",
        "print(classification_report([labels], [predictions]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "intel",
      "language": "python",
      "name": "intel"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    },
    "vscode": {
      "interpreter": {
        "hash": "4981e871006f387a758d8b217761d2bc7da5b52f6761fd904d79e89d82ad62f5"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "14dbdaea90324715a168f7591e8eb48d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d32cd3c6aeeb44e380595fb609561be3",
            "max": 47214,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_483c44bec4554ede82495f285d43176c",
            "value": 47214
          }
        },
        "1a74c9ada2704cb79102e8144bca4726": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "26e341946878457bb6953ce7ba89cf4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2de20674a3d74872b42ad2062b8581f1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f7c57578d8b4908b3a8948799a470bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_84d7731978c842c190b12040e91ed5fd",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_748fd90c77b1431bac28fbc9b39fdd0a",
            "value": "â€‡379k/?â€‡[00:00&lt;00:00,â€‡12.9MB/s]"
          }
        },
        "3493b80dab444e5fbbe1647c265e6e01": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "483c44bec4554ede82495f285d43176c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4f5f62eac87a4d42a7c32139c8ecb7a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ec374625811848e08c60567544d648a1",
              "IPY_MODEL_14dbdaea90324715a168f7591e8eb48d",
              "IPY_MODEL_2f7c57578d8b4908b3a8948799a470bc"
            ],
            "layout": "IPY_MODEL_b6f4ffd6c5b244f8a7bd5ffd3678a23e"
          }
        },
        "584f77a1ccee4646b3ec3cc1ad9c1e8d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "748fd90c77b1431bac28fbc9b39fdd0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "84d7731978c842c190b12040e91ed5fd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "851d36bad58d490ba1057877b5b08222": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86455d32ac5642c0b03847bc4bb3a3d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_584f77a1ccee4646b3ec3cc1ad9c1e8d",
            "max": 47214,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9b1d7397b9be4b3abecd2ab646b36336",
            "value": 47214
          }
        },
        "9b1d7397b9be4b3abecd2ab646b36336": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a772903fa9ad4897b91aae1b4d4cbf79": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bf189cad37784751bb9b646c878252e7",
              "IPY_MODEL_86455d32ac5642c0b03847bc4bb3a3d1",
              "IPY_MODEL_abd87cfbc9b6479b9bf4c1a0d70cd5a1"
            ],
            "layout": "IPY_MODEL_851d36bad58d490ba1057877b5b08222"
          }
        },
        "abd87cfbc9b6479b9bf4c1a0d70cd5a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f2adfbefae714b4e93e0d42871070b3d",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_26e341946878457bb6953ce7ba89cf4a",
            "value": "â€‡379k/?â€‡[00:00&lt;00:00,â€‡12.1MB/s]"
          }
        },
        "b6ebe390285444c9a5dba67c79df461c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b6f4ffd6c5b244f8a7bd5ffd3678a23e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf189cad37784751bb9b646c878252e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3493b80dab444e5fbbe1647c265e6e01",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_1a74c9ada2704cb79102e8144bca4726",
            "value": "Downloadingâ€‡https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json:â€‡"
          }
        },
        "d32cd3c6aeeb44e380595fb609561be3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec374625811848e08c60567544d648a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2de20674a3d74872b42ad2062b8581f1",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_b6ebe390285444c9a5dba67c79df461c",
            "value": "Downloadingâ€‡https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json:â€‡"
          }
        },
        "f2adfbefae714b4e93e0d42871070b3d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
