{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json: 373kB [00:00, 2.83MB/s]                    \n",
      "2024-03-15 15:48:20 INFO: Downloaded file to C:\\Users\\okechukwu chude\\stanza_resources\\resources.json\n",
      "2024-03-15 15:48:20 INFO: Downloading these customized packages for language: en (English)...\n",
      "====================================\n",
      "| Processor       | Package        |\n",
      "------------------------------------\n",
      "| tokenize        | mimic          |\n",
      "| pos             | mimic_charlm   |\n",
      "| lemma           | mimic_nocharlm |\n",
      "| depparse        | mimic_charlm   |\n",
      "| ner             | i2b2           |\n",
      "| forward_charlm  | mimic          |\n",
      "| pretrain        | mimic          |\n",
      "| backward_charlm | mimic          |\n",
      "====================================\n",
      "\n",
      "2024-03-15 15:48:20 INFO: File exists: C:\\Users\\okechukwu chude\\stanza_resources\\en\\tokenize\\mimic.pt\n",
      "2024-03-15 15:48:20 INFO: File exists: C:\\Users\\okechukwu chude\\stanza_resources\\en\\pos\\mimic_charlm.pt\n",
      "2024-03-15 15:48:21 INFO: File exists: C:\\Users\\okechukwu chude\\stanza_resources\\en\\lemma\\mimic_nocharlm.pt\n",
      "2024-03-15 15:48:21 INFO: File exists: C:\\Users\\okechukwu chude\\stanza_resources\\en\\depparse\\mimic_charlm.pt\n",
      "2024-03-15 15:48:21 INFO: File exists: C:\\Users\\okechukwu chude\\stanza_resources\\en\\ner\\i2b2.pt\n",
      "2024-03-15 15:48:21 INFO: File exists: C:\\Users\\okechukwu chude\\stanza_resources\\en\\forward_charlm\\mimic.pt\n",
      "2024-03-15 15:48:21 INFO: File exists: C:\\Users\\okechukwu chude\\stanza_resources\\en\\pretrain\\mimic.pt\n",
      "2024-03-15 15:48:21 INFO: File exists: C:\\Users\\okechukwu chude\\stanza_resources\\en\\backward_charlm\\mimic.pt\n",
      "2024-03-15 15:48:21 INFO: Finished downloading models and saved to C:\\Users\\okechukwu chude\\stanza_resources\n",
      "2024-03-15 15:48:21 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n",
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json: 373kB [00:00, 1.76MB/s]                    \n",
      "2024-03-15 15:48:22 INFO: Downloaded file to C:\\Users\\okechukwu chude\\stanza_resources\\resources.json\n",
      "2024-03-15 15:48:23 INFO: Loading these models for language: en (English):\n",
      "==============================\n",
      "| Processor | Package        |\n",
      "------------------------------\n",
      "| tokenize  | mimic          |\n",
      "| pos       | mimic_charlm   |\n",
      "| lemma     | mimic_nocharlm |\n",
      "| depparse  | mimic_charlm   |\n",
      "| ner       | i2b2           |\n",
      "==============================\n",
      "\n",
      "2024-03-15 15:48:23 INFO: Using device: cpu\n",
      "2024-03-15 15:48:23 INFO: Loading: tokenize\n",
      "2024-03-15 15:48:23 INFO: Loading: pos\n",
      "2024-03-15 15:48:24 INFO: Loading: lemma\n",
      "2024-03-15 15:48:24 INFO: Loading: depparse\n",
      "2024-03-15 15:48:24 INFO: Loading: ner\n",
      "2024-03-15 15:48:24 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import stanza\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "# Build an English pipeline\n",
    "stanza.download('en', package='mimic', processors={'ner': 'i2b2'}) # download English model\n",
    "nlp = stanza.Pipeline('en', package='mimic', processors={'ner': 'i2b2'}) # initialize English neural pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_info_from_json(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    hadm_id = data.get(\"hadm_id\", None)\n",
    "    comment = data.get(\"comment\", None)\n",
    "    notes = data.get(\"notes\", [])\n",
    "    \n",
    "    extracted_data = []\n",
    "    for note in notes:\n",
    "        note_id = note.get(\"note_id\", None)\n",
    "        category = note.get(\"category\", None)\n",
    "        description = note.get(\"description\", None)\n",
    "        annotations = note.get(\"annotations\", [])\n",
    "        text = note.get(\"text\", None)\n",
    "        \n",
    "        for annotation in annotations:\n",
    "            begin = annotation.get(\"begin\", None)\n",
    "            end = annotation.get(\"end\", None)\n",
    "            code = annotation.get(\"code\", None)\n",
    "            code_system = annotation.get(\"code_system\", None)\n",
    "            description = annotation.get(\"description\", None)\n",
    "            covered_text = annotation.get(\"covered_text\", None)\n",
    "            \n",
    "            extracted_data.append({\n",
    "                \"hadm_id\": hadm_id,\n",
    "                \"comment\": comment,\n",
    "                \"note_id\": note_id,\n",
    "                \"category\": category,\n",
    "                \"description\": description,\n",
    "                \"begin\": begin,\n",
    "                \"end\": end,\n",
    "                \"code\": code,\n",
    "                \"code_system\": code_system,\n",
    "                \"covered_text\": covered_text,\n",
    "                \"text\": text\n",
    "            })\n",
    "    \n",
    "    return extracted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to search folders and subfolders for JSON files\n",
    "def search_json_files(root_folder):\n",
    "    json_files = []\n",
    "    for foldername, _, filenames in os.walk(root_folder):\n",
    "        for filename in filenames:\n",
    "            if filename.endswith('.json'):\n",
    "                json_files.append(os.path.join(foldername, filename))\n",
    "    return json_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main function to process all JSON files\n",
    "def process_json_files(root_folder):\n",
    "    all_data = []\n",
    "    json_files = search_json_files(root_folder)\n",
    "    for file_path in json_files:\n",
    "        all_data.extend(extract_info_from_json(file_path))\n",
    "    return all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the root folder containing JSON files\n",
    "root_folder = r\"C:\\Users\\okechukwu chude\\Documents\\NLP\\text extraction\\Automating-Medical-Coding\\2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process JSON files and store extracted information in a DataFrame\n",
    "data = process_json_files(root_folder)\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>comment</th>\n",
       "      <th>note_id</th>\n",
       "      <th>category</th>\n",
       "      <th>description</th>\n",
       "      <th>begin</th>\n",
       "      <th>end</th>\n",
       "      <th>code</th>\n",
       "      <th>code_system</th>\n",
       "      <th>covered_text</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100197</td>\n",
       "      <td></td>\n",
       "      <td>25762</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>Intracerebral hemorrhage</td>\n",
       "      <td>374</td>\n",
       "      <td>377</td>\n",
       "      <td>431</td>\n",
       "      <td>ICD-9-CM</td>\n",
       "      <td>IPH</td>\n",
       "      <td>Admission Date:  [**2136-10-23**]             ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100197</td>\n",
       "      <td></td>\n",
       "      <td>25762</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>Intracerebral hemorrhage</td>\n",
       "      <td>383</td>\n",
       "      <td>409</td>\n",
       "      <td>431</td>\n",
       "      <td>ICD-9-CM</td>\n",
       "      <td>intraventricular extension</td>\n",
       "      <td>Admission Date:  [**2136-10-23**]             ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100197</td>\n",
       "      <td></td>\n",
       "      <td>25762</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>Obstructive hydrocephalus</td>\n",
       "      <td>430</td>\n",
       "      <td>443</td>\n",
       "      <td>331.4</td>\n",
       "      <td>ICD-9-CM</td>\n",
       "      <td>hydrocephalus</td>\n",
       "      <td>Admission Date:  [**2136-10-23**]             ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100197</td>\n",
       "      <td></td>\n",
       "      <td>25762</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>Intracerebral hemorrhage</td>\n",
       "      <td>835</td>\n",
       "      <td>862</td>\n",
       "      <td>431</td>\n",
       "      <td>ICD-9-CM</td>\n",
       "      <td>intraparenchymal hemorrhage</td>\n",
       "      <td>Admission Date:  [**2136-10-23**]             ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100197</td>\n",
       "      <td></td>\n",
       "      <td>25762</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>Do not resuscitate status</td>\n",
       "      <td>1577</td>\n",
       "      <td>1580</td>\n",
       "      <td>V49.86</td>\n",
       "      <td>ICD-9-CM</td>\n",
       "      <td>DNR</td>\n",
       "      <td>Admission Date:  [**2136-10-23**]             ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   hadm_id comment  note_id           category                description  \\\n",
       "0   100197            25762  Discharge summary   Intracerebral hemorrhage   \n",
       "1   100197            25762  Discharge summary   Intracerebral hemorrhage   \n",
       "2   100197            25762  Discharge summary  Obstructive hydrocephalus   \n",
       "3   100197            25762  Discharge summary   Intracerebral hemorrhage   \n",
       "4   100197            25762  Discharge summary  Do not resuscitate status   \n",
       "\n",
       "   begin   end    code code_system                 covered_text  \\\n",
       "0    374   377     431    ICD-9-CM                          IPH   \n",
       "1    383   409     431    ICD-9-CM   intraventricular extension   \n",
       "2    430   443   331.4    ICD-9-CM                hydrocephalus   \n",
       "3    835   862     431    ICD-9-CM  intraparenchymal hemorrhage   \n",
       "4   1577  1580  V49.86    ICD-9-CM                          DNR   \n",
       "\n",
       "                                                text  \n",
       "0  Admission Date:  [**2136-10-23**]             ...  \n",
       "1  Admission Date:  [**2136-10-23**]             ...  \n",
       "2  Admission Date:  [**2136-10-23**]             ...  \n",
       "3  Admission Date:  [**2136-10-23**]             ...  \n",
       "4  Admission Date:  [**2136-10-23**]             ...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to tokenize text using Stanza\n",
    "def tokenize_with_stanza(text):\n",
    "    doc = nlp(text)\n",
    "    tokens = [word.text for sent in doc.sentences for word in sent.words]\n",
    "    return tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the words in the text column\n",
    "df['tokenized_text'] = df['text'].apply(tokenize_with_stanza)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>comment</th>\n",
       "      <th>note_id</th>\n",
       "      <th>category</th>\n",
       "      <th>description</th>\n",
       "      <th>begin</th>\n",
       "      <th>end</th>\n",
       "      <th>code</th>\n",
       "      <th>code_system</th>\n",
       "      <th>covered_text</th>\n",
       "      <th>text</th>\n",
       "      <th>tokenized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100197</td>\n",
       "      <td></td>\n",
       "      <td>25762</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>Intracerebral hemorrhage</td>\n",
       "      <td>374</td>\n",
       "      <td>377</td>\n",
       "      <td>431</td>\n",
       "      <td>ICD-9-CM</td>\n",
       "      <td>IPH</td>\n",
       "      <td>Admission Date:  [**2136-10-23**]             ...</td>\n",
       "      <td>[Admission, Date, :, [, **2136-10-23, **], Dis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100197</td>\n",
       "      <td></td>\n",
       "      <td>25762</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>Intracerebral hemorrhage</td>\n",
       "      <td>383</td>\n",
       "      <td>409</td>\n",
       "      <td>431</td>\n",
       "      <td>ICD-9-CM</td>\n",
       "      <td>intraventricular extension</td>\n",
       "      <td>Admission Date:  [**2136-10-23**]             ...</td>\n",
       "      <td>[Admission, Date, :, [, **2136-10-23, **], Dis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100197</td>\n",
       "      <td></td>\n",
       "      <td>25762</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>Obstructive hydrocephalus</td>\n",
       "      <td>430</td>\n",
       "      <td>443</td>\n",
       "      <td>331.4</td>\n",
       "      <td>ICD-9-CM</td>\n",
       "      <td>hydrocephalus</td>\n",
       "      <td>Admission Date:  [**2136-10-23**]             ...</td>\n",
       "      <td>[Admission, Date, :, [, **2136-10-23, **], Dis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100197</td>\n",
       "      <td></td>\n",
       "      <td>25762</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>Intracerebral hemorrhage</td>\n",
       "      <td>835</td>\n",
       "      <td>862</td>\n",
       "      <td>431</td>\n",
       "      <td>ICD-9-CM</td>\n",
       "      <td>intraparenchymal hemorrhage</td>\n",
       "      <td>Admission Date:  [**2136-10-23**]             ...</td>\n",
       "      <td>[Admission, Date, :, [, **2136-10-23, **], Dis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100197</td>\n",
       "      <td></td>\n",
       "      <td>25762</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>Do not resuscitate status</td>\n",
       "      <td>1577</td>\n",
       "      <td>1580</td>\n",
       "      <td>V49.86</td>\n",
       "      <td>ICD-9-CM</td>\n",
       "      <td>DNR</td>\n",
       "      <td>Admission Date:  [**2136-10-23**]             ...</td>\n",
       "      <td>[Admission, Date, :, [, **2136-10-23, **], Dis...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   hadm_id comment  note_id           category                description  \\\n",
       "0   100197            25762  Discharge summary   Intracerebral hemorrhage   \n",
       "1   100197            25762  Discharge summary   Intracerebral hemorrhage   \n",
       "2   100197            25762  Discharge summary  Obstructive hydrocephalus   \n",
       "3   100197            25762  Discharge summary   Intracerebral hemorrhage   \n",
       "4   100197            25762  Discharge summary  Do not resuscitate status   \n",
       "\n",
       "   begin   end    code code_system                 covered_text  \\\n",
       "0    374   377     431    ICD-9-CM                          IPH   \n",
       "1    383   409     431    ICD-9-CM   intraventricular extension   \n",
       "2    430   443   331.4    ICD-9-CM                hydrocephalus   \n",
       "3    835   862     431    ICD-9-CM  intraparenchymal hemorrhage   \n",
       "4   1577  1580  V49.86    ICD-9-CM                          DNR   \n",
       "\n",
       "                                                text  \\\n",
       "0  Admission Date:  [**2136-10-23**]             ...   \n",
       "1  Admission Date:  [**2136-10-23**]             ...   \n",
       "2  Admission Date:  [**2136-10-23**]             ...   \n",
       "3  Admission Date:  [**2136-10-23**]             ...   \n",
       "4  Admission Date:  [**2136-10-23**]             ...   \n",
       "\n",
       "                                      tokenized_text  \n",
       "0  [Admission, Date, :, [, **2136-10-23, **], Dis...  \n",
       "1  [Admission, Date, :, [, **2136-10-23, **], Dis...  \n",
       "2  [Admission, Date, :, [, **2136-10-23, **], Dis...  \n",
       "3  [Admission, Date, :, [, **2136-10-23, **], Dis...  \n",
       "4  [Admission, Date, :, [, **2136-10-23, **], Dis...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-15 15:55:29 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n",
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json: 373kB [00:00, 76.5MB/s]                    \n",
      "2024-03-15 15:55:30 INFO: Downloaded file to C:\\Users\\okechukwu chude\\stanza_resources\\resources.json\n",
      "2024-03-15 15:55:30 WARNING: Language en package default expects mwt, which has been added\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.8.0/models/tokenize/combined.pt: 100%|██████████| 651k/651k [00:01<00:00, 365kB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.8.0/models/mwt/combined.pt: 100%|██████████| 616k/616k [00:01<00:00, 449kB/s]\n",
      "2024-03-15 15:55:38 INFO: Loading these models for language: en (English):\n",
      "========================\n",
      "| Processor | Package  |\n",
      "------------------------\n",
      "| tokenize  | combined |\n",
      "| mwt       | combined |\n",
      "========================\n",
      "\n",
      "2024-03-15 15:55:38 INFO: Using device: cpu\n",
      "2024-03-15 15:55:38 INFO: Loading: tokenize\n",
      "2024-03-15 15:55:38 INFO: Loading: mwt\n",
      "2024-03-15 15:55:38 INFO: Done loading processors!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       tokenized_text\n",
      "0   [Admission, Date, :, [**2136-10-23, **, ], Dis...\n",
      "1   [Admission, Date, :, [**2136-10-23, **, ], Dis...\n",
      "2   [Admission, Date, :, [**2136-10-23, **, ], Dis...\n",
      "3   [Admission, Date, :, [**2136-10-23, **, ], Dis...\n",
      "4   [Admission, Date, :, [**2136-10-23, **, ], Dis...\n",
      "5   [Admission, Date, :, [**2136-10-23, **, ], Dis...\n",
      "6   [Admission, Date, :, [**2136-10-23, **, ], Dis...\n",
      "7   [Admission, Date, :, [**2136-10-23, **, ], Dis...\n",
      "8   [Admission, Date, :, [**2136-10-23, **, ], Dis...\n",
      "9   [Admission, Date, :, [**2136-10-23, **, ], Dis...\n",
      "10  [Admission, Date, :, [**2136-10-23, **, ], Dis...\n"
     ]
    }
   ],
   "source": [
    "nlp = stanza.Pipeline('en', processors='tokenize')\n",
    "\n",
    "\n",
    "# Function to tokenize text into individual words using Stanza\n",
    "def tokenize_into_words(text):\n",
    "    doc = nlp(text)\n",
    "    words = [word.text for sent in doc.sentences for word in sent.words]\n",
    "    return words\n",
    "\n",
    "# Tokenize the words in the text column\n",
    "df['tokenized_text'] = df['text'].apply(tokenize_into_words)\n",
    "\n",
    "# Create a new DataFrame with only the tokenized text column\n",
    "tokenized_df = pd.DataFrame(df['tokenized_text'])\n",
    "\n",
    "# Display the new DataFrame with only the tokenized text column\n",
    "print(tokenized_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of                                        tokenized_text\n",
       "0   [Admission, Date, :, [**2136-10-23, **, ], Dis...\n",
       "1   [Admission, Date, :, [**2136-10-23, **, ], Dis...\n",
       "2   [Admission, Date, :, [**2136-10-23, **, ], Dis...\n",
       "3   [Admission, Date, :, [**2136-10-23, **, ], Dis...\n",
       "4   [Admission, Date, :, [**2136-10-23, **, ], Dis...\n",
       "5   [Admission, Date, :, [**2136-10-23, **, ], Dis...\n",
       "6   [Admission, Date, :, [**2136-10-23, **, ], Dis...\n",
       "7   [Admission, Date, :, [**2136-10-23, **, ], Dis...\n",
       "8   [Admission, Date, :, [**2136-10-23, **, ], Dis...\n",
       "9   [Admission, Date, :, [**2136-10-23, **, ], Dis...\n",
       "10  [Admission, Date, :, [**2136-10-23, **, ], Dis...>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_df.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
