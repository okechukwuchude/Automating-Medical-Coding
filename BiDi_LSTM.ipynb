{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Bidirectional, LSTM, Dense, Embedding\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/home/chudeo/project/Evidence_sentences.csv')\n",
    "sentences = data['sentence'].tolist()\n",
    "labels = [label.split(',') for label in data['word_labels']]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the sentences\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(sentences)\n",
    "sequences = tokenizer.texts_to_sequences(sentences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the maximum sequence length\n",
    "max_len = max(len(seq) for seq in sequences)\n",
    "\n",
    "# Pad the sequences\n",
    "X = pad_sequences(sequences, maxlen=max_len, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "\n",
    "# Convert labels to numerical values\n",
    "unique_labels = set([label for labels_list in labels for label in labels_list])\n",
    "label_to_id = {label: i for i, label in enumerate(unique_labels)}\n",
    "y = [[label_to_id[label] for label in labels_list] for labels_list in labels]\n",
    "y = pad_sequences(y, maxlen=max_len, padding='post')\n",
    "y = [to_categorical(seq, num_classes=len(unique_labels)) for seq in y]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the Bidirectional LSTM model:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the Bidirectional LSTM model\n",
    "model = Sequential()\n",
    "model.add(Embedding(len(tokenizer.word_index) + 1, 128))\n",
    "model.add(Bidirectional(LSTM(64, return_sequences=True)))\n",
    "model.add(Dense(len(unique_labels), activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 105ms/step - accuracy: 0.9093 - loss: 0.2052 - val_accuracy: 0.9783 - val_loss: 0.0652\n",
      "Epoch 2/10\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 100ms/step - accuracy: 0.9810 - loss: 0.0571 - val_accuracy: 0.9786 - val_loss: 0.0651\n",
      "Epoch 3/10\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 100ms/step - accuracy: 0.9833 - loss: 0.0506 - val_accuracy: 0.9805 - val_loss: 0.0593\n",
      "Epoch 4/10\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 99ms/step - accuracy: 0.9844 - loss: 0.0455 - val_accuracy: 0.9805 - val_loss: 0.0584\n",
      "Epoch 5/10\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 99ms/step - accuracy: 0.9850 - loss: 0.0429 - val_accuracy: 0.9810 - val_loss: 0.0584\n",
      "Epoch 6/10\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 99ms/step - accuracy: 0.9857 - loss: 0.0398 - val_accuracy: 0.9808 - val_loss: 0.0593\n",
      "Epoch 7/10\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 102ms/step - accuracy: 0.9867 - loss: 0.0372 - val_accuracy: 0.9810 - val_loss: 0.0589\n",
      "Epoch 8/10\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 98ms/step - accuracy: 0.9870 - loss: 0.0358 - val_accuracy: 0.9809 - val_loss: 0.0603\n",
      "Epoch 9/10\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 98ms/step - accuracy: 0.9879 - loss: 0.0331 - val_accuracy: 0.9806 - val_loss: 0.0620\n",
      "Epoch 10/10\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 98ms/step - accuracy: 0.9885 - loss: 0.0310 - val_accuracy: 0.9808 - val_loss: 0.0662\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7fef275949a0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X, np.array(y), epochs=10, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 35ms/step - accuracy: 0.9890 - loss: 0.0293\n",
      "Loss: 0.0360, Accuracy: 0.9875\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X, np.array(y))\n",
    "print(f'Loss: {loss:.4f}, Accuracy: {accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_entities(text):\n",
    "    sequence = tokenizer.texts_to_sequences([text])\n",
    "    padded_sequence = pad_sequences(sequence, maxlen=max_len, padding='post')\n",
    "    predictions = model.predict(padded_sequence)\n",
    "    predicted_labels = [[list(unique_labels)[np.argmax(label)] for label in prediction] for prediction in predictions[0]]\n",
    "    return predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 34ms/step\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Predict labels for the data\n",
    "predictions = model.predict(X)\n",
    "predicted_labels = np.argmax(predictions, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert one-hot encoded labels to single labels\n",
    "true_labels = np.argmax(np.array(y), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[1116092     544    7035]\n",
      " [    398    2988    4291]\n",
      " [   2358     747   92985]]\n"
     ]
    }
   ],
   "source": [
    "# Generate confusion matrix\n",
    "conf_matrix = confusion_matrix(true_labels.flatten(), predicted_labels.flatten())\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           B       1.00      0.99      1.00   1123671\n",
      "           I       0.70      0.39      0.50      7677\n",
      "           O       0.89      0.97      0.93     96090\n",
      "\n",
      "    accuracy                           0.99   1227438\n",
      "   macro avg       0.86      0.78      0.81   1227438\n",
      "weighted avg       0.99      0.99      0.99   1227438\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate classification report\n",
    "report = classification_report(true_labels.flatten(), predicted_labels.flatten(), target_names=list(unique_labels))\n",
    "print(\"Classification Report:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "using_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d1a69bf678df178a0a83c1bc249e551d0589a35527ff82fba5716df60535a642"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
